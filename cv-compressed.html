<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Derek Rosenzweig - CV</title>
    <style>
        body {
            font-family: "Times New Roman", Times, serif;
            font-size: 11pt;
            line-height: 1.6;
            color: #000; /* Ensures all text is black */
            margin: 20px;
        }
        h1, h2, h3, h4 {
            margin-top: 25px;
            margin-bottom: 10px;
            color: #000; /* Ensures headers are black */
            font-weight: bold; /* All headers are bold */
        }
        h1 {
            display: inline;
            font-size: 24pt;
        }
        .contact-links {
            display: block;
            margin-top: 10px;
        }
        .contact-links a {
            margin-right: 15px;
            text-decoration: none;
            color: #004080; /* Dark blue for links */
        }
        .contact-links a:hover {
            text-decoration: underline;
        }
        hr {
            margin-top: 40px;
        }
        ul {
            margin-top: 5px;
            margin-bottom: 10px;
        }
        .skills-section {
            margin-top: 30px;
        }
        .skills-section ul {
            columns: 2;
        }
    </style>
</head>
<body>

<!-- Header Section -->
<h1>Derek Rosenzweig</h1>
<div class="contact-links">
    <a href="mailto:derek.rosenzweig1@gmail.com">derek.rosenzweig1@gmail.com</a> |
    <a href="https://github.com/dr2633" target="_blank">GitHub</a> |
    <a href="https://www.linkedin.com/in/derek-rosenzweig-511644114" target="_blank">LinkedIn</a>
</div>

<hr>

<!-- About Me Section -->
<h2>About</h2>


        <p>
         focus on <strong>AI safety</strong>, specifically in <strong>model evaluations</strong> and Reinforcement Learning from Human Feedback (<strong>RLHF</strong>). My work is driven by the challenge of aligning AI systems with human values and user needs, with a focus on optimizing these systems for long-term goals that benefit individuals and organizations. I have a strong interest in <strong>eliciting preferences</strong> from both models and users to enhance security and improve performance in human-AI interaction.

        </p>
        <p>
        For more details on my research approach, see my blog post: <a href="../files/reverse-eval.pdf">Reverse Evaluations: Modeling Reward Functions from User Interaction</a>.
        </p>
        <p>
        Though my current work focuses on AI safety, my experience in <strong>computational neuroscience</strong> has shaped my approach to aligning sensor data across temporal scales. In my past research, I developed methods for decoding speech from neural data and aligning neural network embeddings with time-resolved brain activity, deepening my understanding of how biological neural networks process auditory and language information.
        </p>
        <p>
        My goal is to contribute to AI systems that are optimized to guide users toward long-term objectives, fostering security and scientific progress.
        </p>
<hr>

<!-- Technical Skills Section -->
<h2>Technical Skills</h2>
<div class="skills-section">
    <ul>
        <li><strong>Programming Languages:</strong> Python, MATLAB, Julia, R, JavaScript</li>
        <li><strong>Machine Learning Frameworks:</strong> PyTorch, TensorFlow, JAX, scikit-learn</li>
    </ul>
</div>

<hr>

    <!-- Projects Section -->
    <section id="projects">
        <h2>Projects</h2>

        <h3><a href="https://github.com/dr2633/Intracranial-Speech">Intracranial Speech Processing</a></h3>
        <ul>
            <li>Developed a pipeline for analyzing stereotactic electroencephalography (sEEG) data aligned with audio and language features in a speech task.</li>
            <li>Created workflows to preprocess neural recordings and extract audio and language features (e.g., GPT-2 embeddings).</li>
            <li>Applied methods to correlate electrode recordings with time-resolved annotations of auditory and language stimuli.</li>
        </ul>

         <h3><a href="https://github.com/dr2633/repo-analyzer">GitHub Repository Structure Analyzer</a></h3>
    <ul>
        <li>Created a tool to extract, analyze, and evaluate GitHub repository structures, generating JSON outputs for structured comparison.</li>
        <li>Implemented batch processing to analyze multiple repositories from a CSV file, enabling large-scale repository evaluations.</li>
        <li>Integrated GitHub API access to automate repository analysis and facilitate refactoring based on best practices.</li>
    </ul>

        <h3><a href="https://github.com/dr2633/CloudPref-METR">CloudPref: Model Evaluation for Cloud Providers</a></h3>
        <ul>
            <li>Developed model evaluations to elicit preferences for cloud providers (AWS, GCP, Azure), assessing and optimizing performance based on specific scenarios.</li>
            <li>Designed methods to rank cloud service providers, balancing cost-effectiveness and deployment efficiency.</li>
        </ul>

    </section>


<!-- Research Experience Section -->
<h2>Research Experience</h2>

<h3>Stanford University, Wu Tsai Neurosciences Institute</h3>
<p><strong>Research Scientist</strong> (2023–Present)</p>
<ul>
    <li>Investigated neural mechanisms of speech processing using stereotactic electroencephalography (sEEG) recordings.</li>
    <li>Applied decoding models to identify neural populations encoding auditory and language features.</li>
    <li>Alignment between embeddings in neural networks (e.g., wav2vec2.0, GPT-2) and neural population responses across recording sites for anatomical localization.</li>
    <li>Developed lab protocols for streamlined data acquisition, preprocessing, and analysis.</li>
</ul>
<p><a href="https://github.com/dr2633/Intracranial-Speech" target="_blank">Stereotactic Electroencephalography and Speech Processing</a></p>

<h3>New York University, Department of Psychology</h3>
<p><strong>Graduate Researcher</strong> (2021–2023)</p>
<ul>
    <li>Conducted research on auditory and language processing at the Poeppel Lab and Max Planck NYU Center for Language, Music, and Emotion.</li>
    <li>Designed and executed behavioral and MEG studies to identify individuals with absolute pitch.</li>
    <li>Used magnetoencephalography (MEG) to measure audiovisual interference during a Stroop task, probing automatic label retrieval in individuals with absolute pitch.</li>
</ul>
<p><a href="files/MA.pdf" target="_blank">Absolute Pitch: Behavioral and MEG Experiments</a></p>

<h3>Cornell University, Department of Government</h3>
<p><strong>Undergraduate Research Assistant</strong> (2018–2020)</p>
<ul>
    <li>Thesis on energy geopolitics and trade dynamics in the South China Sea, analyzing the economic and security impacts of territorial disputes.</li>
    <li>Teaching assistant for a course on the science of social behavior, assisting with curriculum development and leading discussions.</li>
</ul>

<hr>

</body>
</html>
